{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EMIT and ENMAP data coverage maps\n",
    "\n",
    "Output in geojson and tif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client\n",
    "\n",
    "def query_emit(bbox= (112, -44., 154, -9.), \n",
    "               timerange=\"2024-01-01T00:00:00Z/2024-12-31T23:59:59Z\",\n",
    "               max_cloud=10):\n",
    "    # LPCLOUD catalog\n",
    "    catalog_url = 'https://cmr.earthdata.nasa.gov/cloudstac/LPCLOUD/'\n",
    "\n",
    "    search_params = {\n",
    "        \"collections\": [\"EMITL2ARFL_001\"],  # Specify the collection\n",
    "        \"bbox\": bbox,      # Define the bounding box (swLon,swLat,neLon,neLat)\n",
    "        \"datetime\": timerange,  # Date range\n",
    "        \"query\": {\n",
    "            \"eo:cloud_cover\": {\"lt\": max_cloud}  # Query parameter: cloud cover less than 10%\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Query STAC catalogls\n",
    "    catalog = pystac_client.Client.open(catalog_url)\n",
    "\n",
    "    # Run the STAC query\n",
    "    query = catalog.search(**search_params)\n",
    "\n",
    "    return list(query.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_enmap(bbox= (112, -44., 154, -9.),\n",
    "                timerange=\"2024-01-01T00:00:00Z/2024-12-31T23:59:59Z\",\n",
    "                max_cloud=10):\n",
    "    \"\"\"\n",
    "    Query the STAC catalog with the specified bounding box and return matching items.\n",
    "\n",
    "    :param bbox: List of [swLon, swLat, neLon, neLat] defining the bounding box.\n",
    "    :return: ItemCollection returned by the query.\n",
    "    \"\"\"\n",
    "    # Open the catalog\n",
    "    catalog_url = \"https://geoservice.dlr.de/eoc/ogc/stac/v1/\"\n",
    "    catalog = pystac_client.Client.open(catalog_url)\n",
    "\n",
    "    # Collections to be searched\n",
    "    collections = [\"ENMAP_HSI_L2A\"]\n",
    "\n",
    "    # Perform the search\n",
    "    search = catalog.search(\n",
    "        collections=collections,\n",
    "        bbox=bbox,\n",
    "        datetime=timerange\n",
    "    )\n",
    "\n",
    "    # Return the items collection\n",
    "    items = search.item_collection()\n",
    "\n",
    "    keep_items=[]\n",
    "    for item in items:\n",
    "        cloud_cover = float(item.properties.get(\"eo:cloud_cover\", 100))  # Default to 100 if not available\n",
    "        biome_type = item.properties.get(\"enmap:biomeType\", 'not available')\n",
    "        if cloud_cover < max_cloud and biome_type != 'not available':\n",
    "            keep_items.append(item)\n",
    "\n",
    "    return keep_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "def parse_datetime(datetime_str):\n",
    "    # Try to parse datetime with and without microseconds\n",
    "    try:\n",
    "        return datetime.strptime(datetime_str, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    except ValueError:\n",
    "        return datetime.strptime(datetime_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    \n",
    "def create_geojson_feature_collection(items, output, sensor=\"emit\"):\n",
    "    features = []\n",
    "\n",
    "    for item in items:\n",
    "        \n",
    "        emit_feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": item.geometry,\n",
    "            \"properties\": {\n",
    "                \"id\": item.id,\n",
    "                \"datetime\": parse_datetime(item.properties[\"datetime\"]).strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"cloud_cover\": float(item.properties[\"eo:cloud_cover\"]),\n",
    "                \"type\": sensor,\n",
    "            }\n",
    "        }\n",
    "\n",
    "        features.append(emit_feature)\n",
    "\n",
    "    feature_collection = {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n",
    "\n",
    "    with open(output, 'w') as f:\n",
    "        json.dump(feature_collection, f, indent=2)\n",
    "\n",
    "    return feature_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio import features\n",
    "from affine import Affine\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def save_to_raster(features_file):\n",
    "    gdf = gpd.read_file(features_file)  # or use gpd.GeoDataFrame for in-memory features\n",
    "\n",
    "    # Define output resolution and bounds\n",
    "    resolution = 0.001  # degrees per pixel\n",
    "    minx, miny, maxx, maxy = gdf.total_bounds\n",
    "    width = int((maxx - minx) / resolution)\n",
    "    height = int((maxy - miny) / resolution)\n",
    "\n",
    "    # Define transform (affine)\n",
    "    transform = Affine.translation(minx, maxy) * Affine.scale(resolution, -resolution)\n",
    "\n",
    "    # Assume you want to count how many times a pixel is covered by any geometry\n",
    "    raster = np.zeros((height, width), dtype=\"uint8\")\n",
    "\n",
    "    gdf['datetime'] = pd.to_datetime(gdf['datetime'])\n",
    "\n",
    "    # Group by date (no time)\n",
    "    gdf['date'] = gdf['datetime'].dt.date\n",
    "    grouped = gdf.groupby('date')\n",
    "    for date, group in grouped:\n",
    "        layer = features.rasterize(\n",
    "            ((geom, 1) for geom in group.geometry),\n",
    "            out_shape=(height, width),\n",
    "            transform=transform,\n",
    "            fill=0,\n",
    "            dtype=\"uint8\"\n",
    "        )\n",
    "        raster += layer  # count overlaps\n",
    "\n",
    "    output = features_file.replace('.geojson','.tif')\n",
    "    # Save to GeoTIFF\n",
    "    with rasterio.open(\n",
    "        output,\n",
    "        \"w\",\n",
    "        driver=\"GTiff\",\n",
    "        height=raster.shape[0],\n",
    "        width=raster.shape[1],\n",
    "        count=1,\n",
    "        dtype=raster.dtype,\n",
    "        crs=gdf.crs.to_string(),\n",
    "        transform=transform,\n",
    "    ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024\n",
    "max_cloud = 10\n",
    "\n",
    "items= query_emit(timerange=f\"{year}-01-01T00:00:00Z/{year}-12-31T23:59:59Z\",\n",
    "               max_cloud=max_cloud)\n",
    "scenes = create_geojson_feature_collection(items, output =f'emit_features_{year}_maxcloud{max_cloud}.geojson')\n",
    "save_to_raster(features_file=f'emit_features_{year}_maxcloud{max_cloud}.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2024\n",
    "max_cloud = 10\n",
    "\n",
    "items= query_enmap(timerange=f\"{year}-01-01T00:00:00Z/{year}-12-31T23:59:59Z\",\n",
    "               max_cloud=max_cloud)\n",
    "scenes = create_geojson_feature_collection(items, output =f'enmap_features_{year}_maxcloud{max_cloud}.geojson', sensor='enmap')\n",
    "save_to_raster(features_file=f'enmap_features_{year}_maxcloud{max_cloud}.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
